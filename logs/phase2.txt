WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work
W0830 14:01:47.755000 34892 torch\distributed\elastic\multiprocessing\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.
=== PHASE 2: Model Evaluation ===

Step 1: Loading test data...
‚úì Loaded 3976 test samples

Step 2: Finding trained models...
Found 3 trained models:
  - models\distiluse-base-multilingual-cased-v2_finetuned
  - models\multilingual-e5-base_finetuned
  - models\paraphrase-multilingual-MiniLM-L12-v2_finetuned

Step 3: Evaluating models...

--- Evaluating Model 1/3: distiluse-base-multilingual-cased-v2_finetuned ---
Loading model from models\distiluse-base-multilingual-cased-v2_finetuned...
Evaluating distiluse-base-multilingual-cased-v2_finetuned...
  Processing 0/100 samples...
  Processing 25/100 samples...
  Processing 50/100 samples...
  Processing 75/100 samples...
‚úì distiluse-base-multilingual-cased-v2_finetuned evaluation completed
‚úì distiluse-base-multilingual-cased-v2_finetuned Results:
  - Exact Match: 0.4101
  - F1 Score: 0.4541
  - Precision: 0.4738
  - Recall: 0.4489
  - Cosine Similarity: 0.9734
  - Evaluation Time: 1.9s

--- Evaluating Model 2/3: multilingual-e5-base_finetuned ---
Loading model from models\multilingual-e5-base_finetuned...
Evaluating multilingual-e5-base_finetuned...
  Processing 0/100 samples...
  Processing 25/100 samples...
  Processing 50/100 samples...
  Processing 75/100 samples...
‚úì multilingual-e5-base_finetuned evaluation completed
‚úì multilingual-e5-base_finetuned Results:
  - Exact Match: 0.3465
  - F1 Score: 0.5992
  - Precision: 0.6674
  - Recall: 0.6444
  - Cosine Similarity: 0.9673
  - Evaluation Time: 3.1s

--- Evaluating Model 3/3: paraphrase-multilingual-MiniLM-L12-v2_finetuned ---
Loading model from models\paraphrase-multilingual-MiniLM-L12-v2_finetuned...
Evaluating paraphrase-multilingual-MiniLM-L12-v2_finetuned...
  Processing 0/100 samples...
  Processing 25/100 samples...
  Processing 50/100 samples...
  Processing 75/100 samples...
‚úì paraphrase-multilingual-MiniLM-L12-v2_finetuned evaluation completed
‚úì paraphrase-multilingual-MiniLM-L12-v2_finetuned Results:
  - Exact Match: 0.4259
  - F1 Score: 0.4973
  - Precision: 0.5697
  - Recall: 0.5165
  - Cosine Similarity: 0.9687
  - Evaluation Time: 2.8s

==================================================
Step 4: Comparing models...
Comparing model performances...
‚úì Model comparison completed

üèÜ BEST MODELS BY METRIC:
  exact_match: paraphrase-multilingual-MiniLM-L12-v2_finetuned (0.4259)
  f1_score: multilingual-e5-base_finetuned (0.5992)
  precision: multilingual-e5-base_finetuned (0.6674)
  recall: multilingual-e5-base_finetuned (0.6444)
  cosine_similarity: distiluse-base-multilingual-cased-v2_finetuned (0.9734)
Results saved to results/phase2_evaluation_results.json
Results saved to results/phase2_model_comparison.json
Results saved to results/phase2_evaluation_results.json
Results saved to results/phase2_model_comparison.json

‚úì Phase 2 completed successfully!
‚úì Evaluated 3 models
‚úì Results saved to results/

üìä SUMMARY:
  exact_match: avg=0.3942, std=0.0343
  f1_score: avg=0.5169, std=0.0608
  precision: avg=0.5703, std=0.0790
  recall: avg=0.5366, std=0.0811
  cosine_similarity: avg=0.9698, std=0.0026